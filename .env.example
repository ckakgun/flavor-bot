# Spoonacular API Configuration
# Get your API key from: https://spoonacular.com/food-api/console#Dashboard
API_KEY=your_spoonacular_api_key_here

# LLM Provider Configuration
# Options: groq, ollama, none
# - groq: Use Groq API (recommended for production, requires GROQ_API_KEY)
# - ollama: Use local Ollama installation (for development, free)
# - none: Disable LLM features (fallback to traditional methods)
LLM_PROVIDER=groq

# Groq API Configuration (required if LLM_PROVIDER=groq)
# Get your API key from: https://console.groq.com/keys
# Free tier: 30 requests/minute, 14,400 requests/day
# Model used: llama-3.1-8b-instant
GROQ_API_KEY=your_groq_api_key_here

# Ollama Configuration (required if LLM_PROVIDER=ollama)
# Install Ollama from: https://ollama.ai
# Run: ollama pull llama3.1:8b
# Then start Ollama service before running the app
# No API key needed for Ollama

# Application Configuration (Optional)
# FLASK_DEBUG=False
# FLASK_PORT=5001
# LOG_LEVEL=INFO
